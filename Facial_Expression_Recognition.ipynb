{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1HAWesXAQP4hKqKhwioO542b4pWhSZCop",
      "authorship_tag": "ABX9TyMSZSNaQcz3GyOxxeCnq/zG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanaa-04/Facial_Expression_Recognition/blob/main/Facial_Expression_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Facial Expression Recognition Using CNN**"
      ],
      "metadata": {
        "id": "xVL_44nwNkPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Facial Expression Recognition using a Convolutional Neural Network delves into the process of interpreting human emotions from images. This tutorial walks you through dataset exploration, model development, training, and evaluation. You'll learn how to design a convolutional neural network and train it to recognize emotions such as happiness and sadness."
      ],
      "metadata": {
        "id": "tGDbmanvAX2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Project Goal:**\n",
        "**The primary goal of DeepFER:** Facial Emotion Recognition Using Deep Learning is to develop an advanced and efficient system capable of accurately identifying and classifying human emotions from facial expressions in real-time. By leveraging state-of-the-art Convolutional Neural Networks (CNNs) and Transfer Learning techniques, this project aims to create a robust model that can handle the inherent variability in facial expressions and diverse image conditions. The system will be trained on a comprehensive dataset featuring seven distinct emotions: angry, sad, happy, fear, neutral, disgust, and surprise. The ultimate objective is to achieve high accuracy and reliability, making DeepFER suitable for applications in human-computer interaction, mental health monitoring, customer service, and beyond. Through this project, we aim to bridge the gap between cutting-edge AI research and practical emotion recognition applications, contributing to more empathetic and responsive machine interactions with humans."
      ],
      "metadata": {
        "id": "-rftE5tgAfBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Emotion Classes:\n",
        "\n",
        "* Angry: Images depicting expressions of anger.\n",
        "* Sad: Images depicting expressions of sadness.\n",
        "* Happy: Images depicting expressions of happiness.\n",
        "* Fear: Images depicting expressions of fear.\n",
        "* Neutral: Images depicting neutral, non-expressive faces.\n",
        "* Disgust: Images depicting expressions of disgust.\n",
        "* Surprise: Images depicting expressions of surprise."
      ],
      "metadata": {
        "id": "JxGnWh_NBIOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Connecting Kaggle to our Colab**"
      ],
      "metadata": {
        "id": "SzpqxVlzNsLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg0a6b88hmPt",
        "outputId": "5e6d27a4-5462-4234-cacc-9cb702cef34a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.2.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.7.9)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/msambare/fer2013\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilE7gmYTh6CI",
        "outputId": "943ade53-affe-43a7-fd29-ab6b9b4f3c26"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: sanamansoori\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/msambare/fer2013\n",
            "Downloading fer2013.zip to ./fer2013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60.3M/60.3M [00:00<00:00, 902MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import Libraries**\n",
        "This section imports the essential libraries needed for constructing and training a convolutional neural network (CNN) for facial expression recognition.\n",
        "\n",
        "* os: Provides functions to interact with the operating system, useful for handling file operations.\n",
        "* cv2: OpenCV library for computer vision, used here for processing images.\n",
        "* numpy: A library for numerical computing, essential for array manipulations.\n",
        "* tensorflow: The TensorFlow library used for deep learning tasks.\n",
        "* train_test_split from sklearn.model_selection: Splits the dataset into training and testing subsets.\n",
        "* ImageDataGenerator from tensorflow.keras.preprocessing.image: Generates batches of augmented data for training.\n",
        "* LabelEncoder from sklearn.preprocessing: Converts categorical labels into numerical format.\n",
        "* to_categorical from keras.utils: Transforms class labels into a binary class matrix.\n",
        "* Sequential from keras.models: A linear stack of layers used to build deep learning models.\n",
        "* Dense, Conv2D, Dropout, BatchNormalization, MaxPooling2D, Flatten from keras.layers: Various layers used in the CNN architecture.\n",
        "* Optimizers (Adam, RMSprop, SGD) from keras.optimizers: Algorithms that adjust model weights during training.\n",
        "* plt from matplotlib.pyplot: A plotting library for visualizing training and validation curves.\n",
        "* Callbacks (ModelCheckpoint, EarlyStopping, ReduceLROnPlateau) from keras.callbacks: Tools used during training to enhance model performance or handle interruptions."
      ],
      "metadata": {
        "id": "8vM-RVpLBSgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, BatchNormalization, MaxPooling2D, Flatten\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "zXpdIUWI6dOa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/fer2013'"
      ],
      "metadata": {
        "id": "Te3DI5hmhaHu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_folders = os.listdir(data_dir)"
      ],
      "metadata": {
        "id": "7NBd58gq6VWE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9u8Cq-v7mv6",
        "outputId": "c2fdee43-4ee3-4d41-dc09-66e16890655f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'test']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accessing the labels\n",
        "def access_labels(data_dir):\n",
        "  \"\"\"\n",
        "  Accesses the labels (emotion categories) from the dataset directory.\n",
        "\n",
        "  Args:\n",
        "    data_dir (str): The path to the root directory of the dataset.\n",
        "\n",
        "  Returns:\n",
        "    list: A list of strings representing the emotion labels.\n",
        "  \"\"\"\n",
        "  train_dir = os.path.join(data_dir, 'train')\n",
        "  # Assuming that the subdirectories in the 'train' folder represent the labels\n",
        "  labels = os.listdir(train_dir)\n",
        "  return labels\n",
        "\n",
        "# Example usage:\n",
        "labels = access_labels(data_dir)\n",
        "print(\"Labels:\", labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohJ4L7uf7nLI",
        "outputId": "e90798d7-0b09-4ed7-fe9f-743285df1e80"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: ['disgust', 'surprise', 'angry', 'happy', 'neutral', 'sad', 'fear']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Appending the label corresponding to the current sub-folder to the list of labels\n",
        "\n",
        "image_paths = []\n",
        "labels_list = []\n",
        "for sub_folder in sub_folders:\n",
        "    folder_path = os.path.join(data_dir, sub_folder)\n",
        "    for emotion_folder in os.listdir(folder_path):\n",
        "        emotion_folder_path = os.path.join(folder_path, emotion_folder)\n",
        "        if os.path.isdir(emotion_folder_path): # Ensure it's a directory\n",
        "            for image_file in os.listdir(emotion_folder_path):\n",
        "                image_path = os.path.join(emotion_folder_path, image_file)\n",
        "                image_paths.append(image_path)\n",
        "                labels_list.append(emotion_folder)\n",
        "\n",
        "print(f\"Total images found: {len(image_paths)}\")\n",
        "print(f\"Total labels found: {len(labels_list)}\")\n",
        "# print(\"First 10 labels:\", labels_list[:10]) # Optional: print first few labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKQnpEoBBqg2",
        "outputId": "14d47685-0309-43c2-ef1b-c9750a1e02b4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images found: 35887\n",
            "Total labels found: 35887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # Converting the lists of images and labels to NumPy arrays\n",
        "\n",
        "import numpy as np\n",
        "images = np.array(image_paths)\n",
        "labels = np.array(labels_list)\n",
        "\n",
        "print(\"Shape of images:\", images.shape)\n",
        "print(\"Shape of labels:\", labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDVBEHLlEXCj",
        "outputId": "10ad7cef-332d-4f83-d56d-ac71ad0c082d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of images: (35887,)\n",
            "Shape of labels: (35887,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjP0RiieG0iw",
        "outputId": "8a374761-17f9-4c88-85ef-f0453a94e643"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is divided into training, validation, and test sets using the train_test_split function from scikit-learn.\n",
        "\n",
        "* X_train, y_train: Images and labels for training.\n",
        "* X_val, y_val: Images and labels for validation.\n",
        "* X_test, y_test: Images and labels for testing.\n",
        "\n",
        "The data is split with 20% allocated to testing and 10% to validation, based on the original dataset. The random_state parameter is set to ensure that the split is reproducible."
      ],
      "metadata": {
        "id": "dW_lYy1iCSgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting Dataset into training, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "9jbwmqdCH-vG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The preprocessing function is created to prepare the input images before passing them into the neural network model.\n",
        "\n",
        "* Normalize the pixel values by dividing them by 255.0, scaling the values to the range [0, 1].\n",
        "* Resize each image to a fixed size of 48x48 pixels using OpenCV's resize function.\n",
        "* Reshape the image array to fit the input format expected by the neural network model. The shape is (batch_size, height, width, channels), where batch_size is -1 to allow for a dynamic batch size, and channels is set to 1 for grayscale images."
      ],
      "metadata": {
        "id": "5lF5WPrkCdDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the image\n",
        "def preprocessing(img_path):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read image from path\n",
        "    img = img / 255.0\n",
        "    img = cv2.resize(img, (48, 48))\n",
        "    return img.reshape(48, 48, 1)  # Reshape to match input shape"
      ],
      "metadata": {
        "id": "bEmx32uiIdK7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code snippet applies the preprocessing function to each image in the training, validation, and test sets using the map function, and then transforms the resulting list of preprocessed images into NumPy arrays.\n",
        "\n",
        "map(preprocessing, X_train): Applies the preprocessing function to every image in X_train.\n",
        "list(map(...)): Converts the map object into a list.\n",
        "np.array(...): Converts the list of preprocessed images into a NumPy array."
      ],
      "metadata": {
        "id": "dcrJRMGXCtNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing to training, validation, and test sets\n",
        "X_train = np.array([preprocessing(img_path) for img_path in X_train])\n",
        "X_val = np.array([preprocessing(img_path) for img_path in X_val])\n",
        "X_test = np.array([preprocessing(img_path) for img_path in X_test])"
      ],
      "metadata": {
        "id": "BVOPR2zrIgeC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code reshapes the input data arrays to eliminate an unnecessary dimension. The neural network model expects input in the shape (batch_size, height, width, channels), where batch_size denotes the number of samples per batch. The extra dimension is removed to match this expected format.\n",
        "\n",
        "* reshape(-1, 48, 48, 1): Adjusts the input data arrays to a shape of (batch_size, 48, 48, 1), where -1 allows the batch size to be dynamically set based on the number of samples."
      ],
      "metadata": {
        "id": "LL4fmomMDMAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape input data to remove unnecessary dimension\n",
        "X_train = X_train.reshape(-1, 48, 48, 1)\n",
        "X_val = X_val.reshape(-1, 48, 48, 1)\n",
        "X_test = X_test.reshape(-1, 48, 48, 1)"
      ],
      "metadata": {
        "id": "SVQ7x-GwIjFq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ImageDataGenerator object is set up with various data augmentation parameters to enhance the training images. Data augmentation is a method used to artificially expand the size of the training dataset by applying random transformations to the images, which helps improve the model's generalization and robustness.\n",
        "\n",
        "* width_shift_range: Randomly shifts the image horizontally by a fraction of its width.\n",
        "* height_shift_range: Randomly shifts the image vertically by a fraction of its height.\n",
        "* zoom_range: Randomly zooms in or out of the image.\n",
        "* shear_range: Applies random shear transformations to the image.\n",
        "* rotation_range: Rotates the image randomly within a specified angle range.\n",
        "\n",
        "After initializing the ImageDataGenerator object, the fit() method is called to compute the necessary statistics for data augmentation based on the training data."
      ],
      "metadata": {
        "id": "qSkxzvzfDgVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize ImageDataGenerator for data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    rotation_range=10\n",
        ")\n",
        "\n",
        "# Compute necessary statistics for data augmentation\n",
        "data_gen.fit(X_train)"
      ],
      "metadata": {
        "id": "jqzCHpj5I4iL"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The LabelEncoder object is initialized to convert class labels into numerical values. This conversion is essential because machine learning models generally require numerical input. The fit() method is then called on the LabelEncoder to train the encoder with the class labels, allowing it to map the labels to their corresponding numerical values."
      ],
      "metadata": {
        "id": "LqGh9ITyDuHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the class labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "LZA2nRlqI7aS",
        "outputId": "6efe9fc8-629e-4bbb-d760-1b8495c70b0a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LabelEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The class labels for the training, validation, and test sets are encoded using the transform() method of the previously initialized LabelEncoder object. This method converts the class labels to their corresponding numerical values based on the mapping established during the fitting process."
      ],
      "metadata": {
        "id": "ASPYsXgaDytN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the class labels for training, validation, and test sets\n",
        "y_train = label_encoder.transform(y_train)\n",
        "y_val = label_encoder.transform(y_val)\n",
        "y_test = label_encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "WBCDFGIOI97C"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variable num_classes is set to the number of unique classes in the dataset, which is obtained from the length of the classes_ attribute of the LabelEncoder object.\n",
        "\n",
        "The to_categorical() function is then employed to convert the encoded class labels into one-hot encoded vectors. This conversion is crucial for multi-class classification tasks, where each class label is represented as a binary vector with a 1 in the position corresponding to the class index and 0s in all other positions."
      ],
      "metadata": {
        "id": "i3kFJv1gD0jP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of classes\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# Convert encoded class labels to one-hot encoded categorical arrays\n",
        "y_train_categorical = to_categorical(y_train, num_classes=num_classes)\n",
        "y_val_categorical = to_categorical(y_val, num_classes=num_classes)\n",
        "y_test_categorical = to_categorical(y_test, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "SE07GKi8JAzd"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *build_model* function defines the architecture of the convolutional neural network (CNN) designed for facial expression recognition.\n",
        "\n",
        "* **1st Layer:** Convolutional layer with 64 filters of size (5, 5), ReLU activation, and batch normalization. This layer is followed by MaxPooling and Dropout layers for regularization.\n",
        "\n",
        "* **2nd Layer:** Convolutional layer with 128 filters of size (3, 3), ReLU activation, and batch normalization, with MaxPooling and Dropout layers added for regularization.\n",
        "\n",
        "* **3rd Layer:** Convolutional layer with 512 filters of size (3, 3), ReLU activation, and batch normalization, accompanied by MaxPooling and Dropout layers for regularization.\n",
        "\n",
        "* **4th Layer:** Convolutional layer with 512 filters of size (3, 3), ReLU activation, and batch normalization, followed by MaxPooling and Dropout layers for regularization.\n",
        "\n",
        "* **Flatten Layer:** Flattens the output from the convolutional layers to prepare it for the fully connected layers.\n",
        "\n",
        "* **Fully Connected Layer 1:** Dense layer with 256 units and ReLU activation, including batch normalization and dropout for regularization.\n",
        "\n",
        "* **Fully Connected Layer 2:** Dense layer with 512 units and ReLU activation, with batch normalization and dropout applied for regularization.\n",
        "\n",
        "* **Output Layer:** Dense layer with softmax activation for multi-class classification, where the number of units corresponds to the number of classes in the dataset.\n",
        "\n",
        "* **Compilation:** The model is compiled using the Adam optimizer, categorical cross-entropy loss function, and accuracy metric."
      ],
      "metadata": {
        "id": "EbscRpeqD7JO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building Model\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    # 1st Layer\n",
        "    model.add(Conv2D(64, (5, 5), strides=(1, 1), padding='same', activation='relu', input_shape=(48, 48, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(2, 2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # 2nd Layer\n",
        "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(2, 2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # 3rd layer\n",
        "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(2, 2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # 4th layer\n",
        "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(2, 2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Flatten Layer\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully connected layer 1\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Fully connected layer 2\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZcznvuWZJHiS"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *summary()* method is invoked on the constructed model to provide an overview of its architecture. This summary includes details on the layers, their output shapes, and the number of trainable parameters."
      ],
      "metadata": {
        "id": "OLiJ1_AYEimi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = build_model()\n",
        "\n",
        "# Print model summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oT7_RSjiKHsg",
        "outputId": "4af6a9f2-f1c5-47f4-fa54-27066c0c1d13"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m1,664\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │       \u001b[38;5;34m590,336\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m3,591\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,348,679\u001b[0m (16.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,348,679</span> (16.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,344,711\u001b[0m (16.57 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,344,711</span> (16.57 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,968\u001b[0m (15.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,968</span> (15.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *ModelCheckpoint* callback is set up to save the model weights during training. It tracks the validation accuracy *(val_acc)* and saves only the best model, as determined by the highest validation accuracy, to the specified file *\"model.h5\"*."
      ],
      "metadata": {
        "id": "4ljGP0wvEqXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize ModelCheckpoint callback\n",
        "# checkpoint = ModelCheckpoint(\"model.h5\", monitor=\"val_acc\", verbose=1, save_best_only=True)\n",
        "# Initialize ModelCheckpoint callback\n",
        "checkpoint = ModelCheckpoint(\"model.keras\", monitor=\"val_acc\", verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "grFPc8rkKKaT"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *EarlyStopping* callback is configured to monitor the validation loss *(val_loss)*. It halts the training process if the validation loss does not improve for a specified number of epochs *(patience)*. This early stopping helps prevent overfitting, and the weights of the best-performing model are restored *(restore_best_weights=True)*."
      ],
      "metadata": {
        "id": "3uAS1pDPEzsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize EarlyStopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "73fXXy7vKRLn"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *ReduceLROnPlateau* callback is configured to adjust the learning rate dynamically during training based on the validation loss *(val_loss)*. If the validation loss does not show improvement for a defined number of epochs *(patience)*, the learning rate is reduced by a specified factor *(factor)*. This adjustment helps enhance the training process and prevents the model from getting stuck in local minima."
      ],
      "metadata": {
        "id": "fTtk9X5-FAIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize ReduceLROnPlateau callback\n",
        "reduce_learningrate = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    min_delta=0.0001\n",
        ")"
      ],
      "metadata": {
        "id": "5RuMWIElKT27"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *callbacks_list* is a list that includes the callbacks to be applied during model training. It consists of the *EarlyStopping*, *ModelCheckpoint*, and *ReduceLROnPlateau* callbacks. These callbacks are used to monitor the validation loss, save the best model, and adjust the learning rate, respectively."
      ],
      "metadata": {
        "id": "9a6sey3fFLmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of callbacks\n",
        "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]"
      ],
      "metadata": {
        "id": "feV1-L7UKWkD"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The compile() method is invoked on the model to set up the training process. It defines the loss function, optimizer, and evaluation metrics to be used during training.\n",
        "\n",
        "* **Loss Function:** Categorical cross-entropy is selected for handling multi-class classification tasks.\n",
        "* **Optimizer:** The Adam optimizer is used with a learning rate of 0.001.\n",
        "* **Metrics:** Accuracy is chosen as the evaluation metric to track the model's performance throughout training.\n"
      ],
      "metadata": {
        "id": "_jIF0aDsFfcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "47EfQf4_KZAn"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fit() method is called on the model to train it using the training data. It accepts the following parameters:\n",
        "\n",
        "* data_gen.flow(X_train, y_train_categorical, batch_size=128): A data generator that produces batches of augmented training data, with on-the-fly data augmentation provided by the ImageDataGenerator object defined earlier.\n",
        "* validation_data=(X_val, y_val_categorical): Validation data used to assess the model's performance after each epoch.\n",
        "* epochs=50: The total number of epochs for training the model.\n",
        "* verbose=1: Determines the verbosity level, with 1 enabling progress bars during training."
      ],
      "metadata": {
        "id": "AFWwSoOkFpKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history = model.fit(\n",
        "    data_gen.flow(X_train, y_train_categorical, batch_size=128),\n",
        "    validation_data=(X_val, y_val_categorical),\n",
        "    epochs=15,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igUPpI3gKbhV",
        "outputId": "15108c22-b71c-4d34-892d-6453d6f1035d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1255s\u001b[0m 6s/step - accuracy: 0.1985 - loss: 2.3539 - val_accuracy: 0.2539 - val_loss: 2.5660\n",
            "Epoch 2/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1252s\u001b[0m 6s/step - accuracy: 0.2887 - loss: 1.8633 - val_accuracy: 0.2539 - val_loss: 3.1421\n",
            "Epoch 3/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1264s\u001b[0m 6s/step - accuracy: 0.3568 - loss: 1.6588 - val_accuracy: 0.3173 - val_loss: 1.9041\n",
            "Epoch 4/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1245s\u001b[0m 6s/step - accuracy: 0.4064 - loss: 1.5317 - val_accuracy: 0.3633 - val_loss: 1.6404\n",
            "Epoch 5/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1224s\u001b[0m 6s/step - accuracy: 0.4502 - loss: 1.4281 - val_accuracy: 0.4361 - val_loss: 1.5413\n",
            "Epoch 6/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1220s\u001b[0m 6s/step - accuracy: 0.4676 - loss: 1.3768 - val_accuracy: 0.4532 - val_loss: 1.4864\n",
            "Epoch 7/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1235s\u001b[0m 6s/step - accuracy: 0.5014 - loss: 1.3102 - val_accuracy: 0.5120 - val_loss: 1.2924\n",
            "Epoch 8/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1230s\u001b[0m 6s/step - accuracy: 0.5156 - loss: 1.2744 - val_accuracy: 0.5444 - val_loss: 1.2221\n",
            "Epoch 9/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1304s\u001b[0m 6s/step - accuracy: 0.5220 - loss: 1.2494 - val_accuracy: 0.5235 - val_loss: 1.2582\n",
            "Epoch 10/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1286s\u001b[0m 6s/step - accuracy: 0.5323 - loss: 1.2181 - val_accuracy: 0.5747 - val_loss: 1.1110\n",
            "Epoch 11/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1330s\u001b[0m 6s/step - accuracy: 0.5459 - loss: 1.1842 - val_accuracy: 0.5357 - val_loss: 1.2426\n",
            "Epoch 12/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1212s\u001b[0m 6s/step - accuracy: 0.5564 - loss: 1.1695 - val_accuracy: 0.5601 - val_loss: 1.1734\n",
            "Epoch 13/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1245s\u001b[0m 6s/step - accuracy: 0.5622 - loss: 1.1589 - val_accuracy: 0.5890 - val_loss: 1.0940\n",
            "Epoch 14/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1245s\u001b[0m 6s/step - accuracy: 0.5688 - loss: 1.1379 - val_accuracy: 0.5514 - val_loss: 1.1844\n",
            "Epoch 15/15\n",
            "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1247s\u001b[0m 6s/step - accuracy: 0.5711 - loss: 1.1245 - val_accuracy: 0.5866 - val_loss: 1.1097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iHb8is3F_wru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the model with .keras extension\n",
        "model.save(\"Custom_CNN_model.keras\")"
      ],
      "metadata": {
        "id": "L2xh4xSMKk6w"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model with .h5 extension\n",
        "model.save('Custom_CNN_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjWPtYE6Xsk6",
        "outputId": "35569860-20c4-4c0f-ced6-5e16bf80bb90"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code snippet plots the model's accuracy over epochs for both training and validation. This visualization helps track the model's performance over time and assists in identifying issues such as overfitting or underfitting."
      ],
      "metadata": {
        "id": "bYVHXsfdF-Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting model performance\n",
        "plt.plot(history.history['accuracy'], label='train_accuracy', marker='o')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy', marker='o')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "hHYq7fcIXvmQ",
        "outputId": "edcc8099-387c-4612-b237-80c2d65e6ae3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Gradio Deployment**"
      ],
      "metadata": {
        "id": "MZXxFC8yGAsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdIedWZDX2RP",
        "outputId": "94380e02-0b68-4efb-de8b-4847eb6c0a15"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "wlUb0bplX73e"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure your model is loaded here\n",
        "# model = ... # Load your trained model\n",
        "# Load your pre-trained model\n",
        "model = tf.keras.models.load_model('/content/Custom_CNN_model.keras')"
      ],
      "metadata": {
        "id": "-80y-fkBYAHN"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Emotion labels dictionary\n",
        "emotion_labels = {'angry': 0, 'disgust': 1, 'fear': 2, 'neutral': 3, 'sad': 4, 'happy': 5, 'surprise': 6}\n",
        "index_to_emotion = {v: k for k, v in emotion_labels.items()}\n",
        "index_to_emotion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Gt1JxMLYD_1",
        "outputId": "543c0b9f-9b28-422a-8512-74f65426ddf4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'angry',\n",
              " 1: 'disgust',\n",
              " 2: 'fear',\n",
              " 3: 'neutral',\n",
              " 4: 'sad',\n",
              " 5: 'happy',\n",
              " 6: 'surprise'}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_image(img_pil):\n",
        "    \"\"\"Preprocess the PIL image to fit your model's input requirements.\"\"\"\n",
        "    # Resize the image to 48x48 pixels\n",
        "    img = img_pil.resize((48, 48))\n",
        "\n",
        "    # If the model expects grayscale images, convert the image to grayscale\n",
        "    img = img.convert('L')\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = img_to_array(img)\n",
        "\n",
        "    # Add a batch dimension (i.e., convert the image to a 4D tensor)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Rescale pixel values to [0, 1] (normalize the data)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    return img_array"
      ],
      "metadata": {
        "id": "skrYwwTdYGLF"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Gradio interface\n",
        "def predict_emotion(image):\n",
        "    # Preprocess the image\n",
        "    processed_image = prepare_image(image)\n",
        "    # Make prediction using the model\n",
        "    prediction = model.predict(processed_image)\n",
        "    # Get the emotion label with the highest probability\n",
        "    predicted_class = np.argmax(prediction, axis=1)\n",
        "    predicted_emotion = index_to_emotion.get(predicted_class[0], \"Unknown Emotion\")\n",
        "    return predicted_emotion"
      ],
      "metadata": {
        "id": "wzx-D8dtYK05"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(\n",
        "    fn=predict_emotion,  # Your prediction function\n",
        "    inputs=gr.Image(type=\"pil\"),  # Input for uploading an image, directly compatible with PIL images\n",
        "    outputs=\"text\",  # Output as text displaying the predicted emotion\n",
        "    title=\"Emotion Detection\",\n",
        "    description=\"Upload an image and see the predicted emotion.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "uq6Uas8LYNIk",
        "outputId": "71cd2a80-9397-4f8b-94c9-054ce20441c2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://31f411c5d73a7d30da.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://31f411c5d73a7d30da.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ]
}